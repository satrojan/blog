---
layout: post
title: The Scraping of Reddit, Part 1
---
The goal of this project is to get data from two different subreddits and attempt to predict which subreddit a post comes from. Because we only have two subreddits we are working with this is a classification problem. To scrape the data I'm using the praw module below.

Importing the modules we'll need.


```python
import requests
import json
import pandas as pd
import datetime
```


```python
datetime.datetime.now().strftime("%Y-%m-%d_%H:%M:%S")
```




    '2018-09-03_14:48:28'



This is the call to the [praw](https://praw.readthedocs.io/en/latest/index.html) module. This makes scraping data from [Reddit](https://www.reddit.com/) much easier. If it wasn't for this wrapper we would need to get and parse a json file. This would be easy as it's just a series of python dictionaries but it would be tedious. All values have been replaced with stars for privacy.


```python
import praw

reddit = praw.Reddit(client_id=****,
                     client_secret=****,
                     user_agent=****,
                     username=****,
                     password=****)


```

This is the function I created to scrape data from Reddit. The values that are collected are the post title, the comments as a Reddit comment tree, the author, if the post was gilded meaning if someone paid Reddit to reward the author of the post, The number of comments, the score which is the number of upvotes and downvotes, the authors flair text, the time created in utc, the post id, and the post body. The function accepts values to select the subreddit, the sorting category (hot, rising, etc.) and the number of posts to scrape. It then takes these values and stores them in a csv file that has a datetime stamp as the filename.


```python
def Reddit_Scraper(sub_reddit, catagory, posts):
    title =[]
    comments=[]
    author=[]
    guilded=[]
    num_comments=[]
    score=[]
    pinned = []
    subreddit=[]
    author_flair_text=[]
    created_utc=[]
    r_id = []
    body=[]

    if catagory == 0:
        cat ='hot'
        for submission in reddit.subreddit(sub_reddit).hot(limit=posts):
            title.append(submission.title)
            comments.append(submission.comments)
            author.append(submission.author)
            guilded.append(submission.gilded)
            num_comments.append(submission.num_comments)
            score.append(submission.score)
            pinned.append(submission.pinned)
            subreddit.append(submission.subreddit)
            author_flair_text.append(submission.author_flair_text)
            created_utc.append(submission.created_utc)
            r_id.append(submission.id)
            body.append(submission.selftext)

    elif catagory == 1:
        cat='new'
        for submission in reddit.subreddit(sub_reddit).new(limit=posts):
            title.append(submission.title)
            comments.append(submission.comments)
            author.append(submission.author)
            guilded.append(submission.gilded)
            num_comments.append(submission.num_comments)
            score.append(submission.score)
            pinned.append(submission.pinned)
            subreddit.append(submission.subreddit)
            author_flair_text.append(submission.author_flair_text)
            created_utc.append(submission.created_utc)
            r_id.append(submission.id)
            body.append(submission.selftext)

    elif catagory==2:
        cat='rising'
        for submission in reddit.subreddit(sub_reddit).rising(limit=posts):
            title.append(submission.title)
            comments.append(submission.comments)
            author.append(submission.author)
            guilded.append(submission.gilded)
            num_comments.append(submission.num_comments)
            score.append(submission.score)
            pinned.append(submission.pinned)
            subreddit.append(submission.subreddit)
            author_flair_text.append(submission.author_flair_text)
            created_utc.append(submission.created_utc)
            r_id.append(submission.id)
            body.append(submission.selftext)


    elif catagory == 3:
        cat='controvertial'
        for submission in reddit.subreddit(sub_reddit).controversial(limit=posts):
            title.append(submission.title)
            comments.append(submission.comments)
            author.append(submission.author)
            guilded.append(submission.gilded)
            num_comments.append(submission.num_comments)
            score.append(submission.score)
            pinned.append(submission.pinned)
            subreddit.append(submission.subreddit)
            author_flair_text.append(submission.author_flair_text)
            created_utc.append(submission.created_utc)
            r_id.append(submission.id)
            body.append(submission.selftext)

    df_temp = pd.DataFrame({'title': title,
                       'comments': comments,
                       'author' :author,
                       'guilded':guilded,
                       'num_comments':num_comments,
                       'score':score,
                       'pinned':pinned,
                       'subreddit':subreddit,
                       'author_flair_text':author_flair_text,
                       'created_utc':created_utc,
                       'r_id':r_id,
                       'body':body})

    tme = datetime.datetime.now().strftime("%Y-%m-%d_%H:%M:%S")
    f_name='{}_{}_{}.csv'.format(tme,cat,sub_reddit)
    df_temp.to_csv(f_name)
```

The original plan involved scraping data from the quasi subreddit "r/popular" I assumed that  getting data from popular and sorting by hot, rising, new and controversial. The hope was that I could detect a post in popular/rising and see if I could predict if it would go to hot, controversial or not go anywhere. That went well but I found that popular/controversial had a large amount of racist material. I did not want to present this to the class so I developed a back up plan.


```python
Reddit_Scraper('popular',0,100)
```


```python
Reddit_Scraper('popular',1,100)
```


```python
Reddit_Scraper('popular',2,100)
```


```python
Reddit_Scraper('popular',3,100)
```

Instead I decided to simply get the posts from ["r/justnomil"](https://www.reddit.com/r/JUSTNOMIL/) and ["r/raisedbynarcissists"](https://www.reddit.com/r/raisedbynarcissists/) instead as they are interesting and have large body posts and not links.

JustNoMil, JNM for short, is a forum for people to complain about their mother in laws. The forum is mostly for stories but there is some requests for advice. It has a upbeat feeling and the members call themselves "drama llamas"

Raised by Narcissists, RBN, is a support group for people that have bad parents. This is a serious subreddit. In hind site I probably should not have used this forum but I was on a deadline.

[Weddingplaning](https://www.reddit.com/r/weddingplanning/) was a backup that was not used


```python
Reddit_Scraper('JUSTNOMIL',0,100)
```


```python
Reddit_Scraper('raisedbynarcissists',0,100)
```


```python
Reddit_Scraper('weddingplanning',0,100)
```
